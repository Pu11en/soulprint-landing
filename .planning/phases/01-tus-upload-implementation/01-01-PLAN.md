---
phase: 01-tus-upload-implementation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - package.json
  - lib/tus-upload.ts
  - app/import/page.tsx
autonomous: true

must_haves:
  truths:
    - "User can upload ChatGPT exports of any size (up to 5GB) without 'file too large' errors"
    - "User sees accurate upload progress percentage that updates smoothly during upload"
    - "User's interrupted upload resumes automatically from where it left off on network reconnect"
    - "User's upload retries automatically on transient server errors (5xx, timeout)"
    - "User's JWT token refreshes automatically during multi-hour uploads (no 401 after 1hr)"
    - "TUS-uploaded files trigger the same RLM processing pipeline as current XHR uploads"
    - "Storage path format is identical to current XHR uploads (imports/{user_id}/{timestamp}-{filename})"
  artifacts:
    - path: "lib/tus-upload.ts"
      provides: "TUS upload wrapper with Supabase-specific configuration"
      exports: ["tusUpload"]
      min_lines: 60
    - path: "app/import/page.tsx"
      provides: "Import page using TUS upload instead of XHR"
      contains: "tusUpload"
    - path: "package.json"
      provides: "tus-js-client dependency"
      contains: "tus-js-client"
  key_links:
    - from: "app/import/page.tsx"
      to: "lib/tus-upload.ts"
      via: "import { tusUpload }"
      pattern: "import.*tusUpload.*tus-upload"
    - from: "lib/tus-upload.ts"
      to: "tus-js-client"
      via: "TUS Upload constructor"
      pattern: "new tus\\.Upload"
    - from: "lib/tus-upload.ts"
      to: "lib/supabase/client.ts"
      via: "Session token refresh in onBeforeRequest"
      pattern: "supabase\\.auth\\.getSession"
    - from: "app/import/page.tsx"
      to: "/api/import/trigger"
      via: "POST after TUS upload completes"
      pattern: "fetch.*api/import/trigger"
---

<objective>
Replace the existing XHR/chunked upload mechanism with TUS resumable uploads to Supabase Storage, enabling reliable uploads of any file size (up to 5GB) on any device/browser.

Purpose: The current XHR upload path hits Supabase Storage REST endpoint limits (~50MB practical ceiling), causing failures for large ChatGPT exports. TUS protocol supports up to 5GB via Supabase Pro with automatic resume on network interruption, 6MB chunk uploads for mobile compatibility, and built-in retry logic.

Output: Working TUS upload flow in `lib/tus-upload.ts` integrated into `app/import/page.tsx`, with the old XHR/chunked upload import replaced. Storage paths and downstream RLM trigger remain identical.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-tus-upload-implementation/01-RESEARCH.md
@lib/chunked-upload.ts
@lib/supabase/client.ts
@app/import/page.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install tus-js-client and create TUS upload wrapper</name>
  <files>
    package.json
    lib/tus-upload.ts
  </files>
  <action>
1. Install tus-js-client:
   ```bash
   npm install tus-js-client
   ```

2. Create `lib/tus-upload.ts` with a `tusUpload` function that wraps tus-js-client for Supabase Storage. The function signature:

   ```typescript
   export interface TusUploadOptions {
     file: Blob;
     userId: string;
     filename: string;
     onProgress: (percent: number) => void;
   }

   export interface TusUploadResult {
     success: boolean;
     storagePath?: string;
     error?: string;
   }

   export async function tusUpload(options: TusUploadOptions): Promise<TusUploadResult>
   ```

3. Implementation details for `tusUpload`:
   - Import `* as tus from 'tus-js-client'` and `createClient from '@/lib/supabase/client'`
   - Get current session via `supabase.auth.getSession()` — return error if no session
   - Build TUS endpoint URL: Extract project ID from `process.env.NEXT_PUBLIC_SUPABASE_URL` (the subdomain before `.supabase.co`). Endpoint: `https://{projectId}.supabase.co/storage/v1/upload/resumable`
   - Build storage object name: `${userId}/${Date.now()}-${sanitizedFilename}` where sanitizedFilename replaces non-alphanumeric chars (except `.` and `-`) with `_`
   - Create `new tus.Upload(file, { ... })` with these EXACT settings:
     - `endpoint`: The TUS endpoint URL constructed above
     - `headers`: `{ authorization: \`Bearer ${session.access_token}\`, apikey: process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY! }`
     - `chunkSize`: `6 * 1024 * 1024` (MUST be 6MB — Supabase requirement, do NOT change)
     - `removeFingerprintOnSuccess`: `true` (prevents fingerprint collision on re-upload)
     - `retryDelays`: `[0, 3000, 5000, 10000, 20000]` (auto-retry with backoff)
     - `metadata`: `{ bucketName: 'imports', objectName, contentType: file.type || 'application/octet-stream', cacheControl: '3600' }`
     - `onBeforeRequest`: async callback that refreshes JWT token before each chunk:
       ```typescript
       async (req: tus.HttpRequest) => {
         const { data: { session: freshSession } } = await supabase.auth.getSession();
         if (!freshSession?.access_token) throw new Error('Session expired during upload');
         req.setHeader('Authorization', `Bearer ${freshSession.access_token}`);
       }
       ```
     - `onProgress`: `(bytesUploaded, bytesTotal) => { onProgress(Math.round((bytesUploaded / bytesTotal) * 100)); }`
     - `onSuccess`: resolve promise with `{ success: true, storagePath: \`imports/${objectName}\` }`
       NOTE: Do NOT try to extract path from `upload.url` — just construct it from the known `objectName` since we control the path format.
     - `onError`: `(error) => { resolve({ success: false, error: error.message }); }`
     - `onShouldRetry`: callback that retries on 401 (after token refresh) and 5xx errors:
       ```typescript
       (err: tus.DetailedError, retryAttempt: number) => {
         const status = err?.originalResponse?.getStatus();
         if (status === 401) return true; // Token refresh handled by onBeforeRequest
         if (status && status >= 500 && status < 600) return retryAttempt < 3;
         return false;
       }
       ```
   - Call `upload.start()` to begin the upload
   - Return the promise

4. Key anti-patterns to AVOID:
   - Do NOT use dynamic chunk sizes or smaller chunks for mobile — MUST be 6MB
   - Do NOT forget `removeFingerprintOnSuccess: true`
   - Do NOT skip `onBeforeRequest` token refresh — uploads >1hr will fail without it
   - Do NOT use `upload.url` to extract storage path — construct it from `objectName`
  </action>
  <verify>
    - `npm ls tus-js-client` shows the package installed
    - `npx tsc --noEmit lib/tus-upload.ts` compiles without errors (or `npm run build` succeeds)
    - `lib/tus-upload.ts` exports `tusUpload`, `TusUploadOptions`, and `TusUploadResult`
    - File contains `chunkSize: 6 * 1024 * 1024`
    - File contains `removeFingerprintOnSuccess: true`
    - File contains `onBeforeRequest` with `getSession()` call
    - File contains `retryDelays`
    - File contains `onShouldRetry`
  </verify>
  <done>
    `lib/tus-upload.ts` exists with a working `tusUpload` function that wraps tus-js-client for Supabase Storage with 6MB chunks, JWT refresh, auto-retry, and fingerprint cleanup. Package `tus-js-client` is installed.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate TUS upload into import page, replacing XHR path</name>
  <files>
    app/import/page.tsx
  </files>
  <action>
1. Update imports at the top of `app/import/page.tsx`:
   - REMOVE: `import { uploadWithProgress, chunkedUpload } from '@/lib/chunked-upload';`
   - ADD: `import { tusUpload } from '@/lib/tus-upload';`

2. In the `processFile` function, replace the entire upload section (approximately lines 510-598, the section between "Use Client-Side Upload" comment and "Upload complete" log) with:

   ```typescript
   // Upload via TUS resumable protocol to Supabase Storage
   setProgressStage('Uploading securely to storage...');
   setProgress(15);

   const supabase = createClient();
   const { data: { user } } = await supabase.auth.getUser();
   if (!user) throw new Error('You must be logged in to upload');

   const blobSizeMB = uploadBlob.size / 1024 / 1024;
   console.log(`[Import] Starting TUS upload: ${blobSizeMB.toFixed(1)}MB mobile=${isMobile}`);
   setProgressStage(`Uploading ${blobSizeMB.toFixed(1)}MB...`);

   const uploadResult = await tusUpload({
     file: uploadBlob,
     userId: user.id,
     filename: uploadFilename,
     onProgress: (percent) => {
       // Map upload progress to 15-50% range
       const mappedProgress = 15 + (percent * 0.35);
       setProgress(Math.round(mappedProgress));
       setProgressStage(`Uploading... ${percent}%`);
     },
   });

   if (!uploadResult.success) {
     console.error('[Import] TUS upload failed:', uploadResult.error);
     throw new Error(uploadResult.error || 'Upload failed');
   }

   const storagePath = uploadResult.storagePath!;
   ```

3. Key integration points to PRESERVE (do NOT change these — they come AFTER the upload):
   - The `console.log('[Import] Upload complete')` line
   - The `setProgressStage('Upload complete! Starting processing...')` line
   - The entire RLM trigger section (`/api/import/trigger` POST)
   - The progress polling section
   - The visibility change handler
   - The error handling in the catch block

4. The `storagePath` variable produced by TUS upload feeds directly into the existing trigger call:
   ```typescript
   body: JSON.stringify({ storagePath }),
   ```
   This is the SAME format as current XHR upload: `imports/{user_id}/{timestamp}-{filename}`. No change needed downstream.

5. Remove the `CHUNKED_THRESHOLD` constant and the if/else branching between chunked and direct XHR upload. TUS handles ALL file sizes uniformly.

6. Remove these now-unused variables/code that only existed for the old XHR path:
   - `const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;` (only used for XHR URL construction)
   - `const contentType = ...` (only used for XHR Content-Type header)
   - `const CHUNKED_THRESHOLD = ...`
   - The `const { data: sessionData } = await supabase.auth.getSession();` and `const accessToken = ...` lines (TUS module handles its own auth)

7. Keep the `isJson` variable (line 508) — it may be used elsewhere, and removing it is harmless if not.
  </action>
  <verify>
    - `npm run build` succeeds without TypeScript errors
    - `app/import/page.tsx` imports `tusUpload` from `@/lib/tus-upload`
    - `app/import/page.tsx` does NOT import from `@/lib/chunked-upload`
    - `app/import/page.tsx` contains `tusUpload({` call
    - `app/import/page.tsx` still contains `fetch('/api/import/trigger'` (downstream trigger preserved)
    - `app/import/page.tsx` still contains progress polling interval code
    - `app/import/page.tsx` still contains visibility change handler code
    - No references to `uploadWithProgress` or `chunkedUpload` or `CHUNKED_THRESHOLD` in import page
  </verify>
  <done>
    `app/import/page.tsx` uses TUS upload for all file sizes. The old XHR/chunked upload code is replaced with a single `tusUpload()` call. Storage path format, RLM trigger, progress polling, and error handling remain unchanged. The build succeeds.
  </done>
</task>

<task type="auto">
  <name>Task 3: Verify build and integration correctness</name>
  <files>
    app/import/page.tsx
    lib/tus-upload.ts
  </files>
  <action>
1. Run full build to catch any TypeScript errors:
   ```bash
   npm run build
   ```

2. Verify the integration is correct by checking:
   - `lib/tus-upload.ts` exists and exports `tusUpload`
   - `app/import/page.tsx` imports from `lib/tus-upload` (not `lib/chunked-upload`)
   - No remaining references to `uploadWithProgress` or `chunkedUpload` in `app/import/page.tsx`
   - `lib/chunked-upload.ts` still exists (cleanup deferred to Phase 2)
   - Storage path format in TUS upload matches existing format: `imports/{user_id}/{timestamp}-{filename}`

3. Verify the `isJson` variable usage: if it's unused after the changes, remove it. If it's used elsewhere in the file, keep it.

4. Fix any build errors. Common issues:
   - tus-js-client type imports may need `import type` for `HttpRequest` or `DetailedError`
   - `onBeforeRequest` callback signature — check tus-js-client TypeScript types
   - If tus-js-client doesn't export types directly, use inline typing

5. Ensure the desktop ZIP extraction flow (JSZip) is preserved — TUS only replaces the upload transport, NOT the client-side extraction logic. The flow should be:
   - Desktop: Extract conversations.json from ZIP -> upload extracted JSON via TUS
   - Mobile: Upload full ZIP via TUS
   This is the SAME logic as before, just the upload transport changes.
  </action>
  <verify>
    - `npm run build` exits with code 0
    - `grep -r 'chunkedUpload\|uploadWithProgress' app/import/page.tsx` returns no results
    - `grep -r 'tusUpload' app/import/page.tsx` returns results
    - `grep -r 'tusUpload' lib/tus-upload.ts` returns results
    - `grep -r 'chunkSize.*6.*1024.*1024' lib/tus-upload.ts` returns results
    - `grep -r 'removeFingerprintOnSuccess.*true' lib/tus-upload.ts` returns results
    - `grep -r 'onBeforeRequest' lib/tus-upload.ts` returns results
  </verify>
  <done>
    Full build passes. TUS upload is correctly integrated into the import flow. Desktop ZIP extraction preserved. Mobile uploads unchanged (just transport layer swapped). No references to old XHR upload in import page. `lib/chunked-upload.ts` still exists for Phase 2 cleanup.
  </done>
</task>

</tasks>

<verification>
1. `npm run build` passes without errors
2. `lib/tus-upload.ts` exists with `tusUpload` export, 6MB chunk size, JWT refresh, retry logic, fingerprint cleanup
3. `app/import/page.tsx` uses `tusUpload` instead of `uploadWithProgress`/`chunkedUpload`
4. Storage path format: `imports/{user_id}/{timestamp}-{sanitized_filename}` (identical to current)
5. RLM trigger flow unchanged: upload -> POST /api/import/trigger -> poll progress
6. Desktop ZIP extraction (JSZip) still works — only transport layer changed
7. No TypeScript errors in modified files
</verification>

<success_criteria>
- Build passes (`npm run build` exits 0)
- TUS wrapper module exists with all required configuration (6MB chunks, JWT refresh, retry, fingerprint cleanup)
- Import page uses TUS for all uploads (no XHR/chunked upload references)
- Storage path format identical to current (no backend changes needed)
- RLM processing pipeline triggered identically after TUS upload
</success_criteria>

<output>
After completion, create `.planning/phases/01-tus-upload-implementation/01-01-SUMMARY.md`
</output>
