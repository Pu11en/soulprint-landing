---
phase: 01-pipeline-reliability
plan: 03
type: execute
wave: 2
depends_on: ["01-01", "01-02"]
files_modified:
  - rlm-service/main.py
  - app/api/import/retry-full-pass/route.ts
  - app/chat/page.tsx
autonomous: true

must_haves:
  truths:
    - "User can click a button in chat to re-trigger a failed full pass without re-uploading"
    - "RLM service accepts POST /retry-full-pass with user_id and storage_path"
    - "Retry uses the original storage_path from user_profiles (no re-upload needed)"
    - "Full pass status resets to 'processing' when retry is triggered"
    - "Retry button only appears when full_pass_status is 'failed'"
  artifacts:
    - path: "rlm-service/main.py"
      provides: "POST /retry-full-pass endpoint"
      contains: "retry-full-pass"
    - path: "app/api/import/retry-full-pass/route.ts"
      provides: "Next.js thin proxy for retry"
      contains: "retry-full-pass"
    - path: "app/chat/page.tsx"
      provides: "Retry button in full pass failure banner"
      contains: "retryFullPass"
  key_links:
    - from: "app/chat/page.tsx"
      to: "app/api/import/retry-full-pass/route.ts"
      via: "fetch POST on button click"
      pattern: "retry-full-pass"
    - from: "app/api/import/retry-full-pass/route.ts"
      to: "rlm-service/main.py"
      via: "HTTP POST to RLM /retry-full-pass"
      pattern: "retry-full-pass"
    - from: "rlm-service/main.py"
      to: "rlm-service/processors/streaming_import.py"
      via: "trigger_full_pass called from retry endpoint"
      pattern: "trigger_full_pass"
---

<objective>
Enable users to re-trigger a failed full pass from the chat interface without re-uploading their export.

Purpose: When the full pass fails (due to Render redeploy, rate limits, timeouts, etc.), users currently have no recourse except to re-upload their entire ChatGPT export. PIPE-05 requires a retry mechanism. The original export file is already in Supabase Storage (referenced by `storage_path` in user_profiles), so we just need to re-trigger the full pass pipeline using that path.

Output: "Retry" button in the chat failure banner, a new Next.js API proxy, and a new RLM endpoint that re-triggers the full pass.
</objective>

<execution_context>
@/home/drewpullen/.claude/get-shit-done/workflows/execute-plan.md
@/home/drewpullen/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@rlm-service/main.py
@rlm-service/processors/streaming_import.py
@app/api/import/trigger/route.ts
@app/chat/page.tsx
@.planning/phases/01-pipeline-reliability/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add RLM /retry-full-pass endpoint and Next.js proxy</name>
  <files>rlm-service/main.py, app/api/import/retry-full-pass/route.ts</files>
  <action>
**rlm-service/main.py — New /retry-full-pass endpoint:**

1. Add a new Pydantic model for the retry request:
   ```python
   class RetryFullPassRequest(BaseModel):
       user_id: str
       storage_path: str
       file_type: str = 'json'
   ```

2. Add a new endpoint `POST /retry-full-pass` that:
   - Accepts `RetryFullPassRequest`
   - Resets `full_pass_status` to "processing" and clears `full_pass_error` via `update_user_profile()`
   - Fires `trigger_full_pass()` from `processors.streaming_import` via `asyncio.create_task()`
   - Returns 202 Accepted immediately
   - The endpoint should import `trigger_full_pass` from `processors.streaming_import`

   ```python
   @app.post("/retry-full-pass")
   async def retry_full_pass(request: RetryFullPassRequest):
       """Re-trigger a failed full pass using the original storage path.
       Returns 202 Accepted immediately -- processing happens in background."""
       from processors.streaming_import import trigger_full_pass

       # Reset status
       await update_user_profile(request.user_id, {
           "full_pass_status": "processing",
           "full_pass_error": None,
       })

       # Fire-and-forget
       asyncio.create_task(trigger_full_pass(
           user_id=request.user_id,
           storage_path=request.storage_path,
           conversation_count=0,  # Unknown on retry, full_pass will re-download and count
           file_type=request.file_type,
       ))

       print(f"[retry-full-pass] Accepted retry for user {request.user_id}")

       return JSONResponse(
           status_code=202,
           content={"status": "accepted", "message": "Full pass retry started"},
       )
   ```

**app/api/import/retry-full-pass/route.ts — Next.js thin proxy:**

3. Create a new route handler that follows the exact same pattern as `app/api/import/trigger/route.ts`:
   - Auth check via Supabase `getUser()`
   - Rate limit check using 'expensive' tier
   - Fetch user's `storage_path` and `full_pass_status` from `user_profiles` using admin client
   - Guard: only allow retry if `full_pass_status === 'failed'` (prevent duplicate triggers)
   - Guard: require `storage_path` to exist (can't retry if original file was never stored — though this shouldn't happen)
   - POST to RLM `${rlmUrl}/retry-full-pass` with `{user_id, storage_path, file_type}`
   - Return 202 on success
   - Use the same error handling pattern as trigger/route.ts

   Key code structure:
   ```typescript
   import { NextResponse } from 'next/server';
   import { createClient } from '@/lib/supabase/server';
   import { createClient as createAdminClient } from '@supabase/supabase-js';
   import { checkRateLimit } from '@/lib/rate-limit';
   import { createLogger } from '@/lib/logger';

   const log = createLogger('API:RetryFullPass');

   export const runtime = 'nodejs';
   export const maxDuration = 30;

   function getSupabaseAdmin() {
     return createAdminClient(
       process.env.NEXT_PUBLIC_SUPABASE_URL!,
       process.env.SUPABASE_SERVICE_ROLE_KEY!,
       { auth: { autoRefreshToken: false, persistSession: false } }
     );
   }

   export async function POST(request: Request) {
     // Auth + rate limit + fetch storage_path from user_profiles
     // Guard: full_pass_status must be 'failed'
     // POST to RLM /retry-full-pass
     // Return 202
   }
   ```

4. The proxy should fetch `storage_path` from user_profiles (the user doesn't need to know or send it). The storage_path was saved during the original import. Also fetch `file_type` if stored, or default to 'json'. Check if `storage_path` column exists in the user_profiles select — it should be the path used in the original import trigger.

   IMPORTANT: Check what column stores the storage path. It might be stored in the original import trigger but NOT persisted to user_profiles. If so, add a note in the action that we need to save it during import. For now, the simplest approach is to select it from user_profiles. If it's not there, we'll need to also update the import trigger to save it.
  </action>
  <verify>
1. Read `rlm-service/main.py` — `/retry-full-pass` endpoint exists, accepts RetryFullPassRequest, returns 202
2. Read `app/api/import/retry-full-pass/route.ts` — auth check, rate limit, full_pass_status guard, RLM call
3. `npm run build` to verify TypeScript compiles
  </verify>
  <done>
New `/retry-full-pass` endpoint on RLM service re-triggers full pass using original storage path. Next.js proxy authenticates user, validates full_pass_status is 'failed', and forwards to RLM.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add retry button to chat full pass failure banner</name>
  <files>app/chat/page.tsx</files>
  <action>
**app/chat/page.tsx — Add retry button to the FullPassBanner:**

1. Add state for retry in progress:
   ```typescript
   const [retryingFullPass, setRetryingFullPass] = useState(false);
   ```

2. Add a retry handler function:
   ```typescript
   const retryFullPass = async () => {
     setRetryingFullPass(true);
     try {
       const res = await fetch('/api/import/retry-full-pass', {
         method: 'POST',
         headers: { 'Content-Type': 'application/json' },
       });
       if (res.ok) {
         setFullPassStatus('processing');
         setFullPassError(null);
         setFullPassDismissed(false);
         // Re-enable polling to track progress
         shouldPoll.current = true;
       } else {
         const data = await res.json().catch(() => ({}));
         console.error('[Chat] Retry failed:', data.error);
       }
     } catch (err) {
       console.error('[Chat] Retry full pass error:', err);
     } finally {
       setRetryingFullPass(false);
     }
   };
   ```

3. Update the `FullPassBanner` component (created in Plan 02) to accept and use `onRetry` and `retrying` props:
   - In the `status === 'failed'` branch, add a retry button:
   ```tsx
   <button
     onClick={onRetry}
     disabled={retrying}
     className="mt-2 rounded-md bg-amber-600 hover:bg-amber-700 dark:bg-amber-700 dark:hover:bg-amber-600 px-3 py-1 text-xs font-medium text-white disabled:opacity-50"
   >
     {retrying ? 'Retrying...' : 'Retry deep memory'}
   </button>
   ```

4. Pass the retry handler and state to the banner:
   ```tsx
   {!fullPassDismissed && (
     <FullPassBanner
       status={fullPassStatus}
       error={fullPassError}
       onDismiss={() => setFullPassDismissed(true)}
       onRetry={retryFullPass}
       retrying={retryingFullPass}
     />
   )}
   ```

5. Include CSRF token in the retry fetch if the project uses CSRF protection. Check `lib/csrf.ts` — the project uses `getCsrfToken()`. Add the CSRF header:
   ```typescript
   import { getCsrfToken } from '@/lib/csrf';
   // In the retry handler:
   const csrfToken = getCsrfToken();
   const res = await fetch('/api/import/retry-full-pass', {
     method: 'POST',
     headers: {
       'Content-Type': 'application/json',
       ...(csrfToken ? { 'x-csrf-token': csrfToken } : {}),
     },
   });
   ```
   Check existing fetch calls in chat/page.tsx for the exact CSRF pattern used and match it.
  </action>
  <verify>
1. Read `app/chat/page.tsx` — retry button exists in FullPassBanner failure state
2. Read `app/chat/page.tsx` — `retryFullPass()` function calls `/api/import/retry-full-pass`
3. Read `app/chat/page.tsx` — retry resets fullPassStatus to 'processing' and re-enables polling
4. `npm run build` to verify TypeScript compiles
  </verify>
  <done>
Users can click "Retry deep memory" button in the chat failure banner. Clicking triggers the retry API, resets status to processing, and re-enables polling to track progress.
  </done>
</task>

</tasks>

<verification>
1. Read `rlm-service/main.py` — `/retry-full-pass` endpoint exists and dispatches background task
2. Read `app/api/import/retry-full-pass/route.ts` — auth, rate limit, status guard, RLM proxy
3. Read `app/chat/page.tsx` — retry button in failure banner, calls API, resets state
4. `npm run build` succeeds
5. Verify: full flow: full pass fails -> banner shows error + retry button -> user clicks retry -> status resets to processing -> banner shows "Building deep memory..." -> full pass completes -> banner disappears
</verification>

<success_criteria>
- User can re-trigger failed full pass from chat UI without re-uploading
- Retry uses original storage_path from user_profiles
- Retry button only shows when full_pass_status is 'failed'
- After retry, status resets to 'processing' and polling resumes
- RLM /retry-full-pass endpoint returns 202 and runs pipeline in background
- Next.js proxy authenticates user and validates status before forwarding
</success_criteria>

<output>
After completion, create `.planning/phases/01-pipeline-reliability/01-03-SUMMARY.md`
</output>
