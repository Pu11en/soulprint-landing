---
phase: 07-production-deployment
plan: 02
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - /home/drewpullen/clawd/soulprint-rlm/ROLLBACK.md
autonomous: false

must_haves:
  truths:
    - "Production RLM on Render runs updated code from Phase 6"
    - "/health endpoint returns 200 with processors_available: true after deploy"
    - "/query endpoint accepts sections parameter and returns personalized response"
    - "Rollback procedure documented for Phase 7 changes"
  artifacts:
    - path: "/home/drewpullen/clawd/soulprint-rlm/ROLLBACK.md"
      provides: "Updated rollback procedure covering Phase 7 prompt changes"
      contains: "Phase 7"
  key_links:
    - from: "Pu11en/soulprint-rlm main branch"
      to: "Render auto-deploy"
      via: "GitHub webhook"
      pattern: "git push origin main"
---

<objective>
Deploy the updated RLM service to Render and verify end-to-end personality works.

Purpose: Plan 01 prepared the code in the production repo. This plan pushes it to GitHub (triggering Render auto-deploy), verifies the deployment succeeded, runs smoke tests, and has the user verify end-to-end personality in the live chat.

Output: Production RLM service running with Phase 6 prompt system, verified healthy and functional, rollback documented.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-production-deployment/07-RESEARCH.md
@.planning/phases/07-production-deployment/07-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Commit, push to production, and update rollback docs</name>
  <files>
    /home/drewpullen/clawd/soulprint-rlm/ROLLBACK.md
  </files>
  <action>
    **Step 1: Commit changes to production repo**

    ```bash
    cd /home/drewpullen/clawd/soulprint-rlm
    git add prompt_helpers.py main.py Dockerfile tests/test_prompt_helpers.py
    git commit -m "feat(07): add Phase 6 prompt foundation

    - Add prompt_helpers.py (clean_section, format_section)
    - Add build_rlm_system_prompt() with anti-generic rules and section formatting
    - Update QueryRequest to accept ai_name, sections, web_search_context
    - Update /query endpoint to use personalized prompts in all intent modes
    - Update Dockerfile to copy and verify prompt_helpers
    - Add prompt_helpers unit tests"
    ```

    **Step 2: Push to GitHub to trigger Render auto-deploy**

    ```bash
    git push origin main
    ```

    This triggers Render's GitHub webhook, which will:
    1. Pull latest code
    2. Run Docker build (including import verification in Dockerfile RUN step)
    3. Start new container
    4. Run health check
    5. Route traffic to new container if healthy

    **Step 3: Wait for deployment and verify health**

    Wait 3-5 minutes for Render to build and deploy, then check:

    ```bash
    # Health check
    curl -s https://soulprint-landing.onrender.com/health | python3 -m json.tool
    ```

    Expected: `"status": "ok"` and `"processors_available": true`.

    If health check fails (503, connection refused, or processors_available: false), check Render logs for import errors. If the issue is with prompt_helpers import, rollback immediately:
    ```bash
    git revert HEAD --no-edit && git push origin main
    ```

    **Step 4: Smoke test /query with sections**

    ```bash
    curl -s -X POST https://soulprint-landing.onrender.com/query \
      -H "Content-Type: application/json" \
      -d '{
        "user_id": "smoke-test",
        "message": "Hello, tell me about yourself",
        "ai_name": "Echo",
        "sections": {
          "soul": {
            "personality_traits": ["curious", "direct", "witty"],
            "communication_style": "Casual and concise, prefers analogies"
          },
          "identity": {
            "signature_greeting": "Hey there, partner!",
            "core_values": ["honesty", "efficiency"]
          }
        }
      }'
    ```

    Verify:
    - Response returns 200 (not 422 validation error, not 500)
    - Response body contains a `response` field with AI-generated text
    - The AI response does NOT contain banned phrases ("Great question!", "I'd be happy to help!")
    - The AI references its name "Echo" or personality traits

    Note: This smoke test uses a fake user_id, so chunk retrieval will return empty. That's fine — we're testing the prompt builder, not the full pipeline.

    **Step 5: Update ROLLBACK.md**

    Update `/home/drewpullen/clawd/soulprint-rlm/ROLLBACK.md` to add Phase 7 context:

    Add a new section covering:
    - When to rollback Phase 7: AI responses are generic (ignoring personality), /query returns 500s, prompt_helpers import fails
    - How to rollback: `git revert HEAD --no-edit && git push origin main`
    - What gets preserved: All database data, all processor pipelines, v1/v2 endpoints
    - What gets lost: Personalized prompts revert to hardcoded "You are SoulPrint" prompts

    Commit the ROLLBACK.md update:
    ```bash
    git add ROLLBACK.md
    git commit -m "docs(07): update rollback procedure for Phase 7 prompt changes"
    git push origin main
    ```
  </action>
  <verify>
    ```bash
    # Verify deployment health
    curl -s https://soulprint-landing.onrender.com/health | grep '"status"'

    # Verify /query accepts new fields
    curl -s -o /dev/null -w "%{http_code}" -X POST https://soulprint-landing.onrender.com/query \
      -H "Content-Type: application/json" \
      -d '{"user_id":"test","message":"hi","ai_name":"Echo","sections":{"soul":{"traits":["curious"]}}}'
    ```
    Health returns 200. Query returns 200 (not 422 or 500).
  </verify>
  <done>
    - git push to Pu11en/soulprint-rlm main branch completed
    - Render deployed successfully (health check 200)
    - /query accepts ai_name and sections parameters
    - ROLLBACK.md updated with Phase 7 rollback procedure
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
    Production RLM service deployed to Render with Phase 6 prompt foundation:
    - Personalized system prompts using structured sections (SOUL, IDENTITY, USER, AGENTS, TOOLS, MEMORY)
    - Anti-generic phrase blocking ("Great question!", "I'd be happy to help!", etc.)
    - Natural memory referencing ("Like we talked about..." not "According to retrieved context...")
    - AI uses its generated name instead of generic "SoulPrint"
  </what-built>
  <how-to-verify>
    1. Open https://soulprint.dev/chat (or your production URL) in a browser
    2. Log in with a test account that has completed the import process (has a generated AI name and personality sections)
    3. Check the initial greeting message — it should be personalized (using the AI's signature greeting from IDENTITY section), NOT "Hello, how can I help you today?"
    4. Send a message like "Tell me about yourself" — the AI should reference its name and personality traits from the SOUL section
    5. Send a follow-up like "What do you know about me?" — the AI should reference information from conversation history naturally
    6. Verify the AI does NOT use banned phrases like "Great question!", "I'd be happy to help!", "Certainly!"
    7. Compare the response quality to what you saw before Phase 6 — it should feel noticeably more personalized

    If the AI still feels generic or doesn't use its name, check:
    - Render dashboard shows "Deploy succeeded" for latest commit
    - /health endpoint returns `processors_available: true`
    - Browser network tab shows the /query request includes `sections` in the payload
  </how-to-verify>
  <resume-signal>Type "approved" if personality works, or describe specific issues you see</resume-signal>
</task>

</tasks>

<verification>
1. `curl https://soulprint-landing.onrender.com/health` returns 200 with processors_available: true
2. `/query` endpoint accepts ai_name and sections parameters (200 response, not 422)
3. AI response uses personalized language (references name, personality traits)
4. AI response does NOT contain banned generic phrases
5. ROLLBACK.md in production repo contains Phase 7 rollback instructions
6. User confirms end-to-end personality works in production chat
</verification>

<success_criteria>
Production RLM service on Render runs Phase 6 prompt code. Health check passes. Smoke test confirms /query accepts new parameters. User verifies personalized chat experience in production. Rollback documented.
</success_criteria>

<output>
After completion, create `.planning/phases/07-production-deployment/07-02-SUMMARY.md`
</output>
