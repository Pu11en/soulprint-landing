---
phase: 01-rlm-ei-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/api/chat/route.ts
  - rlm-service/main.py
autonomous: true

must_haves:
  truths:
    - "TypeScript chat route passes emotional_state and relationship_arc to RLM service in API request"
    - "Python RLM service receives EI parameters via QueryRequest Pydantic model"
    - "Python PromptBuilder uses build_emotionally_intelligent_prompt() method in both RLM primary path and fallback path"
    - "RLM responses reflect emotional context (warm tone when user is happy, supportive when anxious)"
  artifacts:
    - path: "app/api/chat/route.ts"
      provides: "tryRLMService updated to pass emotional_state and relationship_arc parameters"
      min_lines: 8
    - path: "rlm-service/main.py"
      provides: "QueryRequest with emotional_state and relationship_arc fields, query_with_rlm and query_fallback use build_emotionally_intelligent_prompt"
      contains: "emotional_state: Optional[dict]"
  key_links:
    - from: "app/api/chat/route.ts"
      to: "RLM_SERVICE_URL/query"
      via: "POST request with emotional_state and relationship_arc in payload"
      pattern: "emotional_state.*relationship_arc"
    - from: "rlm-service/main.py"
      to: "prompt_builder.build_emotionally_intelligent_prompt"
      via: "Pass emotional_state and relationship_arc from request to builder"
      pattern: "build_emotionally_intelligent_prompt.*emotional_state.*relationship_arc"
---

<objective>
Wire emotional intelligence parameters through the TypeScript chat route to the Python RLM service, ensuring both RLM primary path and Bedrock fallback produce emotionally intelligent responses.

Purpose: Currently, only the Bedrock fallback path uses emotional intelligence parameters (detected emotion and relationship arc). The RLM primary path bypasses these features, creating inconsistent user experiences. This plan wires the existing EI infrastructure from TypeScript through HTTP to Python, changing zero business logic — just passing parameters that already exist.

Output: TypeScript passes EI params to RLM, Python receives and uses them in prompt construction, both paths produce emotionally adaptive responses.
</objective>

<execution_context>
@./.claude/agents/gsd-planner.md
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-rlm-ei-integration/01-RESEARCH.md
@app/api/chat/route.ts
@rlm-service/main.py
@rlm-service/prompt_builder.py
@lib/soulprint/emotional-intelligence.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Pass EI Parameters from TypeScript to RLM Service</name>
  <files>app/api/chat/route.ts</files>
  <action>
Modify the TypeScript chat route to pass emotional intelligence parameters to the RLM service.

**Step 1: Update tryRLMService function signature** (line 142-150):
Add two optional parameters to the function signature:
```typescript
async function tryRLMService(
  userId: string,
  message: string,
  soulprintText: string | null,
  history: ChatMessage[],
  webSearchContext?: string,
  aiName?: string,
  sections?: Record<string, unknown> | null,
  // ADD these two:
  emotionalState?: EmotionalState,
  relationshipArc?: { stage: 'early' | 'developing' | 'established'; messageCount: number },
): Promise<RLMResponse | null> {
```

**Step 2: Add EI parameters to fetch payload** (line 165-173):
Update the body JSON to include emotional_state and relationship_arc:
```typescript
body: JSON.stringify({
  user_id: userId,
  message,
  soulprint_text: soulprintText,
  history,
  web_search_context: webSearchContext,
  ai_name: aiName,
  sections: sections || undefined,
  // ADD these two:
  emotional_state: emotionalState,
  relationship_arc: relationshipArc,
}),
```

**Step 3: Pass EI parameters in tryRLMService call** (line 372-380):
Update the function call to include the emotionalState and relationshipArc variables that already exist in scope (lines 325 and 334):
```typescript
const rlmResponse = await tryRLMService(
  user.id,
  message,
  userProfile?.soulprint_text || null,
  history,
  webSearchContext || undefined,
  aiName,
  hasSections ? sections : null,
  // ADD these two (already in scope):
  emotionalState,
  relationshipArc,
);
```

**What NOT to change:**
- Do NOT modify emotion detection logic (lines 324-344) — it already works correctly
- Do NOT add new EI detection — we're passing existing values
- Do NOT modify the Bedrock fallback path (line 459+) — it already uses EI correctly
  </action>
  <verify>
Run `npx tsc --noEmit` to verify no TypeScript errors. Grep for "emotional_state" and "relationship_arc" in the fetch body to confirm parameters are included.
  </verify>
  <done>
tryRLMService function signature includes emotionalState and relationshipArc parameters, fetch payload includes both fields, and call site passes the detected EI values.
  </done>
</task>

<task type="auto">
  <name>Task 2: Receive and Use EI Parameters in Python RLM Service</name>
  <files>rlm-service/main.py</files>
  <action>
Modify the Python RLM service to receive emotional intelligence parameters and use them when building prompts.

**Step 1: Update QueryRequest Pydantic model** (line 40-48):
Add two optional fields to the QueryRequest class:
```python
class QueryRequest(BaseModel):
    user_id: str
    message: str
    soulprint_text: Optional[str] = None
    history: Optional[List[dict]] = []
    ai_name: Optional[str] = None
    sections: Optional[dict] = None  # {soul, identity, user, agents, tools, memory}
    web_search_context: Optional[str] = None
    # ADD these two:
    emotional_state: Optional[dict] = None
    relationship_arc: Optional[dict] = None
```

**Step 2: Update query_with_rlm function signature** (line 297-305):
Add EI parameters to the function:
```python
async def query_with_rlm(
    message: str,
    conversation_context: str,
    soulprint_text: str,
    history: List[dict],
    ai_name: str = "SoulPrint",
    sections: Optional[dict] = None,
    web_search_context: Optional[str] = None,
    # ADD these two:
    emotional_state: Optional[dict] = None,
    relationship_arc: Optional[dict] = None,
) -> str:
```

**Step 3: Use build_emotionally_intelligent_prompt in query_with_rlm** (line 321-326):
REPLACE the call to `build_system_prompt` with `build_emotionally_intelligent_prompt`:
```python
# CHANGE from build_system_prompt to build_emotionally_intelligent_prompt
system_prompt = builder.build_emotionally_intelligent_prompt(
    profile=profile,
    ai_name=ai_name,
    memory_context=conversation_context,
    web_search_context=web_search_context,
    emotional_state=emotional_state,
    relationship_arc=relationship_arc,
)
```

**Step 4: Update query_fallback function signature** (around line 343):
Add the same two parameters to query_fallback:
```python
async def query_fallback(
    message: str,
    conversation_context: str,
    soulprint_text: str,
    history: List[dict],
    ai_name: str = "SoulPrint",
    sections: Optional[dict] = None,
    web_search_context: Optional[str] = None,
    # ADD these two:
    emotional_state: Optional[dict] = None,
    relationship_arc: Optional[dict] = None,
) -> str:
```

**Step 5: Use build_emotionally_intelligent_prompt in query_fallback**:
Find the `build_system_prompt` call in query_fallback (similar location to query_with_rlm) and replace with:
```python
system_prompt = builder.build_emotionally_intelligent_prompt(
    profile=profile,
    ai_name=ai_name,
    memory_context=conversation_context,
    web_search_context=web_search_context,
    emotional_state=emotional_state,
    relationship_arc=relationship_arc,
)
```

**Step 6: Update /query endpoint to pass EI params** (around line 414-473):
In the query() endpoint handler, pass the new parameters from request to both query_with_rlm and query_fallback:
```python
# In the try block (RLM path):
response = await query_with_rlm(
    message=request.message,
    conversation_context=conversation_context,
    soulprint_text=request.soulprint_text or "",
    history=request.history or [],
    ai_name=ai_name,
    sections=request.sections,
    web_search_context=request.web_search_context,
    # ADD these two:
    emotional_state=request.emotional_state,
    relationship_arc=request.relationship_arc,
)

# In the except block (fallback path):
response = await query_fallback(
    message=request.message,
    conversation_context=conversation_context,
    soulprint_text=request.soulprint_text or "",
    history=request.history or [],
    ai_name=ai_name,
    sections=request.sections,
    web_search_context=request.web_search_context,
    # ADD these two:
    emotional_state=request.emotional_state,
    relationship_arc=request.relationship_arc,
)
```

**What NOT to change:**
- Do NOT modify prompt_builder.py — build_emotionally_intelligent_prompt() already exists from v2.0 Phase 3
- Do NOT duplicate emotion detection in Python — use the TypeScript-detected values
- Do NOT add defensive null checks — PromptBuilder.build_emotionally_intelligent_prompt() already handles None safely
  </action>
  <verify>
Run `python -m py_compile rlm-service/main.py` to verify no syntax errors. Grep for "build_emotionally_intelligent_prompt" in main.py to confirm both query_with_rlm and query_fallback use the EI prompt method. Grep for "emotional_state" in QueryRequest to confirm Pydantic model includes the field.
  </verify>
  <done>
QueryRequest model includes emotional_state and relationship_arc fields, both query_with_rlm and query_fallback use build_emotionally_intelligent_prompt instead of build_system_prompt, and the /query endpoint passes EI parameters to both functions.
  </done>
</task>

<task type="auto">
  <name>Task 3: Verify Cross-Language EI Wiring</name>
  <files>None (verification only)</files>
  <action>
Run the existing cross-language sync tests to verify emotional intelligence parameters flow correctly from TypeScript to Python.

**Step 1: Verify TypeScript compiles:**
```bash
npx tsc --noEmit
```
Expect: Zero errors (confirms TypeScript changes are type-safe)

**Step 2: Verify Python syntax:**
```bash
python -m py_compile rlm-service/main.py
```
Expect: No output (confirms Python changes compile)

**Step 3: Run cross-language EI sync test:**
```bash
npx vitest run __tests__/cross-lang/emotional-intelligence-sync.test.ts
```
Expect: All tests pass (confirms PromptBuilder methods produce character-identical output)

**Step 4: Verify wiring with grep:**
```bash
# Confirm TypeScript passes EI params
grep -A 5 "emotional_state.*relationship_arc" app/api/chat/route.ts

# Confirm Python receives EI params
grep "emotional_state: Optional\[dict\]" rlm-service/main.py

# Confirm Python uses EI prompt method
grep "build_emotionally_intelligent_prompt" rlm-service/main.py
```
Expect: All three patterns found

**What success looks like:**
- TypeScript compiles without errors
- Python compiles without errors
- Cross-language sync tests pass (existing tests, no new tests needed)
- Grep confirms wiring is complete in both files
  </action>
  <verify>
All verification commands pass: tsc compiles cleanly, Python compiles, cross-language tests pass, grep patterns found.
  </verify>
  <done>
TypeScript and Python compile without errors, cross-language EI sync tests pass, grep confirms emotional_state and relationship_arc flow from TypeScript fetch → Python QueryRequest → PromptBuilder.build_emotionally_intelligent_prompt().
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with no errors
2. `python -m py_compile rlm-service/main.py` succeeds
3. `npx vitest run __tests__/cross-lang/emotional-intelligence-sync.test.ts` passes
4. Grep confirms TypeScript sends EI params in fetch payload
5. Grep confirms Python QueryRequest has emotional_state and relationship_arc fields
6. Grep confirms both query_with_rlm and query_fallback use build_emotionally_intelligent_prompt
7. No modifications to prompt_builder.py (uses existing v2.0 Phase 3 code)
</verification>

<success_criteria>
- TypeScript chat route passes emotional_state and relationship_arc to RLM service in fetch payload
- Python QueryRequest Pydantic model includes emotional_state and relationship_arc fields
- Both query_with_rlm and query_fallback call build_emotionally_intelligent_prompt instead of build_system_prompt
- Cross-language EI sync tests pass (confirms character-identical prompt output)
- No new dependencies added (pure wiring of existing infrastructure)
- All code compiles without type errors in both TypeScript and Python
</success_criteria>

<output>
After completion, create `.planning/phases/01-rlm-ei-integration/01-01-SUMMARY.md`
</output>
