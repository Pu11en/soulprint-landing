---
phase: 04-quality-scoring
plan: 03
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - app/api/cron/quality-refinement/route.ts
  - app/api/quality/score/route.ts
  - app/api/import/process-server/route.ts
  - vercel.json
autonomous: true
user_setup:
  - service: supabase
    why: "Run SQL migration for quality_breakdown column"
    dashboard_config:
      - task: "Execute migration 20260209_quality_breakdown.sql in SQL Editor"
        location: "Supabase Dashboard -> SQL Editor -> paste migration contents"

must_haves:
  truths:
    - "Soulprints scoring below 60 on any metric are automatically flagged for refinement"
    - "Background refinement job improves flagged soulprints without user intervention"
    - "Quality scoring runs after import completes without blocking the import flow"
  artifacts:
    - path: "app/api/cron/quality-refinement/route.ts"
      provides: "Background cron job that finds and refines low-quality profiles"
      exports: ["GET"]
    - path: "app/api/quality/score/route.ts"
      provides: "Manual trigger endpoint to score a specific profile"
      exports: ["POST"]
    - path: "vercel.json"
      provides: "Cron schedule for quality refinement (daily)"
      contains: "quality-refinement"
  key_links:
    - from: "app/api/cron/quality-refinement/route.ts"
      to: "lib/evaluation/quality-scoring.ts"
      via: "Imports calculateQualityBreakdown and hasLowQualityScores"
      pattern: "import.*calculateQualityBreakdown|hasLowQualityScores"
    - from: "app/api/import/process-server/route.ts"
      to: "lib/evaluation/quality-scoring.ts"
      via: "Triggers quality scoring after import_status = quick_ready"
      pattern: "calculateQualityBreakdown"
    - from: "app/api/cron/quality-refinement/route.ts"
      to: "RLM_SERVICE_URL/create-soulprint"
      via: "Calls RLM to re-generate low-quality sections"
      pattern: "RLM_SERVICE_URL"
---

<objective>
Create the background quality refinement cron job, a manual scoring endpoint, and hook quality scoring into the import pipeline so profiles are scored automatically after generation.

Purpose: QUAL-03 requires automatic flagging and refinement of low-quality soulprints. The cron job runs daily, finds profiles with any metric below 60, calls RLM to re-generate those sections, and re-scores them. The import pipeline hook ensures every new profile gets quality scores without user intervention. The manual endpoint allows dev/admin triggering.

Output: Cron route, manual score endpoint, import pipeline integration, vercel.json cron schedule.
</objective>

<execution_context>
@./.claude/agents/gsd-planner.md
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-quality-scoring/04-RESEARCH.md
@.planning/phases/04-quality-scoring/04-01-SUMMARY.md
@app/api/cron/tasks/route.ts
@app/api/import/process-server/route.ts
@vercel.json
@lib/evaluation/quality-scoring.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Quality Refinement Cron Job</name>
  <files>app/api/cron/quality-refinement/route.ts, vercel.json</files>
  <action>
**Part A: Create `app/api/cron/quality-refinement/route.ts`**

Follow the exact pattern from `app/api/cron/tasks/route.ts`:
- Lazy-initialized Supabase admin client (same pattern: module-level `_supabaseAdmin` variable with `getSupabaseAdmin()` function)
- CRON_SECRET auth header verification (same pattern: allow in dev, enforce in production)
- Process max 10 profiles per run to avoid Vercel function timeout

Implementation:

1. **Find low-quality profiles**: Call `supabase.rpc('find_low_quality_profiles', { threshold_score: 60 })` using the SQL function created in Plan 01's migration. Limit to 10 results.

2. **For each profile**: Load the full profile including `soul_md, identity_md, user_md, agents_md, tools_md, quality_breakdown`.

3. **Identify which sections need refinement**: Check quality_breakdown for each section -- if ANY of its three metrics (completeness, coherence, specificity) is below 60, that section needs refinement.

4. **Refine each low-quality section**: Call the existing RLM `/create-soulprint` endpoint (NOT a new endpoint -- use the existing one from `RLM_SERVICE_URL`) to re-generate the section. The refinement call should:
   - Send the user's existing conversation chunks (query from `conversation_chunks` table, limit 50 chunks for the refinement prompt)
   - Include current section content in the prompt with instruction: "Improve this section. Preserve existing personality traits. Add missing details, fix contradictions, and increase specificity. Do NOT change core personality characteristics."
   - If RLM call fails, log error and skip (never block other profiles)

5. **Re-score refined sections**: After successful refinement, call `scoreSoulprintSection()` from `quality-scoring.ts` on only the refined section (not all 5 -- that's wasteful).

6. **Update database atomically**: Update the section content (`{section}_md`) AND quality_breakdown AND quality_scored_at in a single update call.

7. **Return summary**: JSON with `{ message, profiles_checked, sections_refined, errors }`.

Import from quality-scoring:
```typescript
import { scoreSoulprintSection, hasLowQualityScores } from '@/lib/evaluation/quality-scoring';
import type { QualityBreakdown, SectionQualityScores } from '@/lib/evaluation/quality-scoring';
```

IMPORTANT: The refinement should use the EXISTING `/create-soulprint` endpoint on RLM, passing a refinement-oriented system prompt. Do NOT assume a `/refine-section` endpoint exists (the research document suggested one, but we should use what exists). Format the request as:
```typescript
const response = await fetch(`${process.env.RLM_SERVICE_URL}/create-soulprint`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    conversations: chunks.map(c => c.content),
    existing_sections: { [sectionType]: currentContent },
    mode: 'refine',
  }),
});
```
If the RLM response does not support `mode: 'refine'`, fall back to calling it normally and extracting just the relevant section from the response.

IMPORTANT: Wrap the entire cron handler in try/catch. Individual profile processing failures must not crash the whole job. Log errors with `console.error` prefixed with `[QualityRefinement]`.

**Part B: Update `vercel.json`**

Add the quality refinement cron to the existing crons array:
```json
{
  "crons": [
    {
      "path": "/api/memory/synthesize",
      "schedule": "0 */6 * * *"
    },
    {
      "path": "/api/cron/quality-refinement",
      "schedule": "0 3 * * *"
    }
  ]
}
```
Schedule: Daily at 3 AM UTC. This avoids peak hours and gives enough time between runs.
  </action>
  <verify>
Run `npx tsc --noEmit app/api/cron/quality-refinement/route.ts` -- no type errors. Verify `vercel.json` is valid JSON with both cron entries. Verify the route exports a GET handler. Verify the RLM call uses `RLM_SERVICE_URL` environment variable.
  </verify>
  <done>
- Cron job finds profiles with any quality metric below 60
- Processes max 10 profiles per run (Vercel timeout safety)
- Re-generates low-quality sections via RLM
- Re-scores only the refined sections (not all 15 dimensions)
- Updates DB atomically (content + scores + timestamp)
- Cron scheduled daily at 3 AM UTC in vercel.json
  </done>
</task>

<task type="auto">
  <name>Task 2: Manual Score Endpoint and Import Pipeline Hook</name>
  <files>app/api/quality/score/route.ts, app/api/import/process-server/route.ts</files>
  <action>
**Part A: Create `app/api/quality/score/route.ts`**

A POST endpoint for manually triggering quality scoring on a profile. Useful for dev/admin and for the import pipeline to call after profile generation.

- Require authentication (check Supabase auth from request)
- Accept JSON body: `{ user_id?: string }` -- if no user_id, score the authenticated user's profile
- Load profile from user_profiles (soul_md, identity_md, user_md, agents_md, tools_md)
- Call `calculateQualityBreakdown(profile)` from quality-scoring.ts
- Save result to `user_profiles.quality_breakdown` and `user_profiles.quality_scored_at`
- Return the breakdown in response: `{ quality_breakdown, scored_at }`
- Add rate limiting: use the existing `checkRateLimit` with 'expensive' tier (20/min) since this triggers 15 LLM calls

Import pattern:
```typescript
import { calculateQualityBreakdown } from '@/lib/evaluation/quality-scoring';
import type { QualityBreakdown } from '@/lib/evaluation/quality-scoring';
import { checkRateLimit } from '@/lib/rate-limit';
import { createClient } from '@/lib/supabase/server';
```

Follow the existing route patterns in the codebase: use `createClient` for authenticated requests (not admin), validate with Zod, return standardized JSON responses.

**Part B: Hook quality scoring into import pipeline**

Modify `app/api/import/process-server/route.ts` to trigger quality scoring AFTER the quick pass completes and sets `import_status = 'quick_ready'` (around line 400).

The scoring should be FIRE-AND-FORGET (non-blocking):
- After setting import_status to 'quick_ready' and the user can start chatting
- Call the quality scoring endpoint internally OR call `calculateQualityBreakdown` directly
- Since quality scoring takes 5-10 seconds (15 LLM calls), it MUST NOT block the import response
- Use a pattern like:

```typescript
// Fire-and-forget quality scoring (do not await)
void (async () => {
  try {
    const breakdown = await calculateQualityBreakdown({
      soul_md: quickPassResult.soul ? JSON.stringify(quickPassResult.soul) : null,
      identity_md: quickPassResult.identity ? JSON.stringify(quickPassResult.identity) : null,
      user_md: quickPassResult.user ? JSON.stringify(quickPassResult.user) : null,
      agents_md: quickPassResult.agents ? JSON.stringify(quickPassResult.agents) : null,
      tools_md: quickPassResult.tools ? JSON.stringify(quickPassResult.tools) : null,
    });

    await adminSupabase
      .from('user_profiles')
      .update({
        quality_breakdown: breakdown,
        quality_scored_at: new Date().toISOString(),
      })
      .eq('user_id', userId);

    console.log(`[Import] Quality scoring complete for ${userId}`);
  } catch (err) {
    console.error(`[Import] Quality scoring failed for ${userId}:`, err);
    // Non-fatal: user can still chat, scores will be calculated by cron later
  }
})();
```

IMPORTANT: The fire-and-forget pattern works on Vercel because the function doesn't return until the response is sent, and the background work continues until the function timeout. However, if the import response is already sent before quality scoring finishes, the Vercel function may terminate. To handle this safely: if the import route already returns before scoring finishes, the daily cron job will catch unscored profiles. Add a check in the cron to also score profiles where `quality_breakdown IS NULL AND import_status IN ('quick_ready', 'complete')`.

IMPORTANT: Do NOT modify the core import flow or error handling. The quality scoring hook is additive-only. If scoring fails, the import should still succeed.
  </action>
  <verify>
Run `npx tsc --noEmit app/api/quality/score/route.ts app/api/import/process-server/route.ts` -- no type errors. Verify the score endpoint exports a POST handler. Verify the import route has the fire-and-forget quality scoring call after quick_ready status. Run `npx vitest run` to confirm no test regressions.
  </verify>
  <done>
- Manual score endpoint at POST `/api/quality/score` with auth and rate limiting
- Import pipeline triggers quality scoring as fire-and-forget after quick pass
- Cron job also catches unscored profiles (quality_breakdown IS NULL with import complete)
- All quality scoring failures are non-fatal (never blocks import or chat)
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with no errors in all modified/created files
2. `npx vitest run` -- all existing tests pass (no regressions)
3. `vercel.json` is valid JSON with quality-refinement cron at 3 AM UTC
4. Cron route handles auth, processes max 10 profiles, updates DB atomically
5. Manual score endpoint requires auth and rate limiting
6. Import pipeline hook is fire-and-forget, non-blocking, non-fatal
</verification>

<success_criteria>
- Background cron job finds and refines profiles with any metric below 60
- New profiles are scored automatically after import completes
- Manual scoring endpoint exists for dev/admin use
- All quality scoring is non-blocking and fail-safe (never crashes import or chat)
- Cron scheduled in vercel.json for daily execution
</success_criteria>

<output>
After completion, create `.planning/phases/04-quality-scoring/04-03-SUMMARY.md`
</output>
