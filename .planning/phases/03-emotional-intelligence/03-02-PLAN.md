---
phase: 03-emotional-intelligence
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - app/api/chat/route.ts
autonomous: true

must_haves:
  truths:
    - "Chat route detects user emotion before generating response"
    - "Chat route queries message count for relationship arc"
    - "Chat route uses dynamic temperature in Bedrock inference config"
    - "Chat route builds emotionally intelligent system prompt via PromptBuilder"
    - "Emotion detection failure does not break chat (graceful degradation)"
  artifacts:
    - path: "app/api/chat/route.ts"
      provides: "Emotionally intelligent chat pipeline with emotion detection, relationship arc, dynamic temperature"
      contains: "detectEmotion"
  key_links:
    - from: "app/api/chat/route.ts"
      to: "lib/soulprint/emotional-intelligence.ts"
      via: "import detectEmotion, getRelationshipArc, determineTemperature"
      pattern: "from.*emotional-intelligence"
    - from: "app/api/chat/route.ts"
      to: "lib/soulprint/prompt-builder.ts"
      via: "buildEmotionallyIntelligentPrompt call"
      pattern: "buildEmotionallyIntelligentPrompt"
    - from: "app/api/chat/route.ts"
      to: "supabase chat_messages count query"
      via: "adminSupabase.from('chat_messages').select count"
      pattern: "chat_messages.*count.*exact"
---

<objective>
Wire emotional intelligence into the chat route so every message gets emotion detection, relationship arc context, and dynamic temperature.

Purpose: This is where EMOT-01 (adaptive response style), EMOT-02 (uncertainty acknowledgment), and EMOT-03 (relationship arc) become user-facing. The chat route orchestrates the EI pipeline: detect emotion -> query relationship depth -> build adaptive prompt -> set dynamic temperature -> generate response.

Output: Modified `app/api/chat/route.ts` with full EI integration in the Bedrock fallback path.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-emotional-intelligence/03-RESEARCH.md
@.planning/phases/03-emotional-intelligence/03-01-SUMMARY.md
@app/api/chat/route.ts
@lib/soulprint/prompt-builder.ts
@lib/soulprint/emotional-intelligence.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate emotion detection and relationship arc into chat route</name>
  <files>app/api/chat/route.ts</files>
  <action>
Modify `app/api/chat/route.ts` to add emotional intelligence to the Bedrock fallback path.

**1. Add imports at top of file:**
```typescript
import {
  detectEmotion,
  getRelationshipArc,
  determineTemperature,
  EmotionalState,
} from '@/lib/soulprint/emotional-intelligence';
```

**2. After the smart search block (around line 313) and before the RLM call, add emotion detection:**

```typescript
// Emotion detection (EMOT-01) -- lightweight, fail-safe
let emotionalState: EmotionalState = { primary: 'neutral', confidence: 0.5, cues: [] };
try {
  emotionalState = await detectEmotion(message, history.slice(-5));
  reqLog.debug({ emotion: emotionalState.primary, confidence: emotionalState.confidence }, 'Emotion detected');
} catch (error) {
  reqLog.warn({ error: error instanceof Error ? error.message : String(error) }, 'Emotion detection failed, defaulting to neutral');
}
```

**3. After emotion detection, add relationship arc query:**

```typescript
// Relationship arc (EMOT-03) -- message count from chat_messages
let relationshipArc: { stage: 'early' | 'developing' | 'established'; messageCount: number } = { stage: 'early', messageCount: 0 };
try {
  const { count: messageCount } = await adminSupabase
    .from('chat_messages')
    .select('*', { count: 'exact', head: true })
    .eq('user_id', user.id);
  relationshipArc = getRelationshipArc(messageCount || 0);
  reqLog.debug({ stage: relationshipArc.stage, messageCount: relationshipArc.messageCount }, 'Relationship arc determined');
} catch (error) {
  reqLog.warn({ error: error instanceof Error ? error.message : String(error) }, 'Relationship arc query failed, defaulting to early');
}
```

**4. In the Bedrock fallback section (around line 427), replace the existing PromptBuilder call:**

Replace:
```typescript
const promptBuilder = new PromptBuilder();
const systemPrompt = promptBuilder.buildSystemPrompt({
  profile: userProfile || { ... },
  dailyMemory: learnedFacts || [],
  memoryContext,
  aiName,
  isOwner: voiceVerified,
  webSearchContext,
  webSearchCitations,
});
```

With:
```typescript
const promptBuilder = new PromptBuilder();
const systemPrompt = promptBuilder.buildEmotionallyIntelligentPrompt({
  profile: userProfile || { soulprint_text: null, import_status: 'none', ai_name: null, soul_md: null, identity_md: null, user_md: null, agents_md: null, tools_md: null, memory_md: null },
  dailyMemory: learnedFacts || [],
  memoryContext,
  aiName,
  isOwner: voiceVerified,
  webSearchContext,
  webSearchCitations,
  emotionalState,
  relationshipArc,
});
```

**5. Add dynamic temperature to the Bedrock ConverseStreamCommand (around line 451):**

Replace:
```typescript
inferenceConfig: {
  maxTokens: 4096,
},
```

With:
```typescript
inferenceConfig: {
  maxTokens: 4096,
  temperature: determineTemperature(message, emotionalState, !!memoryContext).temperature,
  // DO NOT set top_p -- Sonnet 4.5/Haiku 4.5 require temperature XOR top_p
},
```

Also log the temperature decision:
```typescript
const tempConfig = determineTemperature(message, emotionalState, !!memoryContext);
reqLog.debug({ temperature: tempConfig.temperature, reason: tempConfig.reason }, 'Dynamic temperature set');
```
Then use `tempConfig.temperature` in the inferenceConfig.

**6. Add emotion and relationship data to Opik spans:**

In the Bedrock fallback Opik span (around line 511), add to metadata:
```typescript
metadata: {
  durationMs: duration,
  fallback: true,
  emotion: emotionalState.primary,
  emotionConfidence: emotionalState.confidence,
  relationshipStage: relationshipArc.stage,
  temperature: tempConfig.temperature,
},
```

**Important considerations:**
- Emotion detection runs BEFORE the RLM call so it's available for both paths
- The RLM path does NOT use buildEmotionallyIntelligentPrompt (RLM builds its own prompts server-side) -- only Bedrock fallback uses it
- All EI operations are wrapped in try/catch with neutral/safe defaults
- The relationship arc query uses `{ count: 'exact', head: true }` for efficient count-only query (no data returned)
  </action>
  <verify>
Run `npx tsc --noEmit` -- no type errors.
Run `npm run build` -- build succeeds.
Verify the chat route file contains: `detectEmotion`, `getRelationshipArc`, `determineTemperature`, `buildEmotionallyIntelligentPrompt`, `chat_messages.*count`.
  </verify>
  <done>
Chat route integrates full EI pipeline: emotion detection -> relationship arc -> emotionally intelligent prompt -> dynamic temperature. All operations fail-safe with neutral defaults. Opik tracing includes EI metadata.
  </done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes
- `npm run build` succeeds
- Chat route imports from `emotional-intelligence.ts`
- Chat route calls `buildEmotionallyIntelligentPrompt` instead of `buildSystemPrompt` in Bedrock path
- Chat route uses dynamic temperature from `determineTemperature`
- Chat route queries `chat_messages` count for relationship arc
- All EI operations wrapped in try/catch
</verification>

<success_criteria>
- Chat messages trigger emotion detection using Haiku 4.5
- Relationship arc is determined from total message count
- System prompt includes uncertainty acknowledgment, relationship tone, and adaptive tone sections
- Temperature dynamically adjusts based on emotion + query type
- Any EI failure gracefully falls back to neutral defaults without breaking chat
</success_criteria>

<output>
After completion, create `.planning/phases/03-emotional-intelligence/03-02-SUMMARY.md`
</output>
