---
phase: 02-copy-modify-processors
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - /home/drewpullen/clawd/soulprint-rlm/tests/test_processors.py
  - /home/drewpullen/clawd/soulprint-rlm/tests/conftest.py
  - /home/drewpullen/clawd/soulprint-rlm/pytest.ini
autonomous: true

must_haves:
  truths:
    - "pytest and pytest-asyncio are present in requirements.txt and importable (verified before test authoring)"
    - "Processor unit tests pass with pytest (exit code 0)"
    - "Pure function tests cover estimate_tokens, chunk_conversations, consolidate_facts, and fallback_memory"
    - "Tests mock external dependencies (Anthropic API) and adapter functions"
    - "pytest.ini coverage includes both adapters/ and processors/ directories"
    - "Existing adapter tests (17 tests) still pass after changes"
  artifacts:
    - path: "tests/test_processors.py"
      provides: "Unit tests for processor-specific logic"
      min_lines: 80
    - path: "tests/conftest.py"
      provides: "Updated shared fixtures including ANTHROPIC_API_KEY mock"
    - path: "pytest.ini"
      provides: "Coverage config including processors/ directory"
  key_links:
    - from: "tests/test_processors.py"
      to: "processors/conversation_chunker.py"
      via: "from processors.conversation_chunker import"
      pattern: "from processors\\.conversation_chunker import"
    - from: "tests/test_processors.py"
      to: "processors/fact_extractor.py"
      via: "from processors.fact_extractor import"
      pattern: "from processors\\.fact_extractor import"
    - from: "tests/test_processors.py"
      to: "processors/memory_generator.py"
      via: "from processors.memory_generator import"
      pattern: "from processors\\.memory_generator import"
    - from: "pytest.ini"
      to: "processors/"
      via: "--cov=processors in addopts"
      pattern: "--cov=processors"
---

<objective>
Write processor unit tests for pure function logic and update pytest configuration to include processors/ in coverage.

Purpose: Satisfies Phase 2 success criteria 3 (processor unit tests pass in isolation with mocked adapter) and 4 (pytest and pytest-asyncio installed and working). Validates that copied processor modules work correctly in production environment.
Output: test_processors.py with focused unit tests, updated conftest.py and pytest.ini.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-copy-modify-processors/02-RESEARCH.md
@.planning/phases/02-copy-modify-processors/02-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update pytest.ini and conftest.py for processor testing</name>
  <files>
    /home/drewpullen/clawd/soulprint-rlm/pytest.ini
    /home/drewpullen/clawd/soulprint-rlm/tests/conftest.py
  </files>
  <action>
    0. Pre-flight: Verify pytest and pytest-asyncio are installed (Phase 1 added these to requirements.txt):
    ```bash
    cd /home/drewpullen/clawd/soulprint-rlm
    grep "pytest" requirements.txt
    python -m pytest --version
    python -c "import pytest_asyncio; print('pytest-asyncio OK')"
    ```
    Confirm both `pytest` and `pytest-asyncio` appear in requirements.txt and are importable. If not, STOP -- Phase 1 setup is incomplete.

    1. Update pytest.ini to add processors/ to coverage:
       Change the addopts line from:
       ```
       addopts =
           --cov=adapters
           --cov-report=term-missing
           -v
       ```
       To:
       ```
       addopts =
           --cov=adapters
           --cov=processors
           --cov-report=term-missing
           -v
       ```

    2. Update tests/conftest.py to add ANTHROPIC_API_KEY mock (needed for processor imports that create anthropic clients):
       Add to the existing mock_env_vars fixture:
       ```python
       monkeypatch.setenv("ANTHROPIC_API_KEY", "test-anthropic-key-12345")
       ```

    3. Add a sample_chunks fixture to conftest.py for processor tests:
       ```python
       @pytest.fixture
       def sample_chunks():
           """Sample chunk data for processor testing."""
           return [
               {
                   "conversation_id": "conv-1",
                   "title": "Test Chat",
                   "content": "User: Hello\nAssistant: Hi there!",
                   "chunk_index": 0,
                   "total_chunks": 1,
                   "chunk_tier": "medium",
                   "message_count": 2,
                   "created_at": "2024-06-01T00:00:00Z",
               }
           ]
       ```

    4. Verify existing adapter tests still pass:
       ```bash
       cd /home/drewpullen/clawd/soulprint-rlm && python -m pytest tests/test_supabase_adapter.py -v
       ```
  </action>
  <verify>
    ```bash
    cd /home/drewpullen/clawd/soulprint-rlm
    # Existing tests still pass
    python -m pytest tests/test_supabase_adapter.py -v
    # Check pytest.ini has processors coverage
    grep "cov=processors" pytest.ini && echo "PASS"
    ```
  </verify>
  <done>pytest.ini includes processors/ in coverage. conftest.py has ANTHROPIC_API_KEY mock and sample_chunks fixture. Existing 17 adapter tests still pass.</done>
</task>

<task type="auto">
  <name>Task 2: Write processor unit tests</name>
  <files>
    /home/drewpullen/clawd/soulprint-rlm/tests/test_processors.py
  </files>
  <action>
    Create /home/drewpullen/clawd/soulprint-rlm/tests/test_processors.py with unit tests for pure processor functions. Focus on testable logic, not external API calls.

    **Test categories to implement:**

    1. **conversation_chunker tests:**
       - `test_estimate_tokens_empty_string`: estimate_tokens("") returns 0
       - `test_estimate_tokens_known_length`: estimate_tokens("a" * 40) returns 10 (40/4)
       - `test_estimate_tokens_short_string`: estimate_tokens("test") returns 1
       - `test_chunk_conversations_single_small_conversation`: One small conversation creates exactly 1 chunk. Use a conversation with a simple messages list: `[{"role": "user", "content": "Hi"}, {"role": "assistant", "content": "Hello"}]`. Pass target_tokens=2000. Verify: len(chunks) == 1, chunk has chunk_index=0, total_chunks=1, chunk_tier="medium".
       - `test_chunk_conversations_empty_list`: Empty conversation list returns empty chunk list.
       - `test_format_conversation_with_messages`: Test format_conversation with simplified format (messages list, not mapping). Verify output contains "User:" and "Assistant:" labels.

    2. **fact_extractor tests:**
       - `test_consolidate_facts_deduplication`: Create a list of fact dicts with duplicates across categories (preferences, communication_style, etc). Call consolidate_facts(). Verify total_count reflects unique facts. The function takes a list of dicts like: `[{"preferences": ["coffee", "tea", "coffee"], "communication_style": ["formal"]}]`. Verify the returned dict has deduplicated lists.
       - `test_consolidate_facts_empty_input`: consolidate_facts([]) returns a dict with empty lists for all categories and total_count=0.

    3. **memory_generator tests:**
       - `test_fallback_memory_with_facts`: Import `_fallback_memory` from memory_generator. Call with a consolidated facts dict that has some facts. Verify it returns a non-empty string containing "# MEMORY" header.
       - `test_fallback_memory_empty_facts`: _fallback_memory with empty facts dict still returns a valid markdown string.

    **Implementation notes:**
    - Import from processors package: `from processors.conversation_chunker import ...`
    - Do NOT test functions that call external APIs (extract_facts_parallel, generate_memory_section, regenerate_sections_v2). Those need mocked HTTP clients -- save for Phase 4 integration tests.
    - Do NOT test adapter functions (already covered by test_supabase_adapter.py).
    - Use the sample_conversations fixture from conftest.py where applicable.
    - All tests should be synchronous (pure functions). No need for async/await.
    - Target: 8-12 focused tests covering critical pure functions.

    **Read the actual source files first** to confirm function signatures and return types:
    - Read processors/conversation_chunker.py to find exact signatures for estimate_tokens, chunk_conversations, format_conversation
    - Read processors/fact_extractor.py to find exact signature for consolidate_facts
    - Read processors/memory_generator.py to find exact signature and name of fallback function (might be _fallback_memory or fallback_memory)

    Adapt test implementations based on actual function signatures found in source code.
  </action>
  <verify>
    ```bash
    cd /home/drewpullen/clawd/soulprint-rlm

    # Run processor tests specifically
    python -m pytest tests/test_processors.py -v

    # Run all tests (adapter + processor)
    python -m pytest tests/ -v

    # Verify coverage includes processors
    python -m pytest tests/ --cov=processors --cov-report=term-missing
    ```
    All processor tests pass. All adapter tests still pass. Coverage report shows processors/ modules.
  </verify>
  <done>test_processors.py has 8+ passing tests covering estimate_tokens, chunk_conversations, format_conversation, consolidate_facts, and fallback_memory. Full test suite (adapter + processor) passes with exit code 0.</done>
</task>

</tasks>

<verification>
Run comprehensive verification:

```bash
cd /home/drewpullen/clawd/soulprint-rlm

# 1. Full test suite passes
python -m pytest tests/ -v

# 2. Coverage includes both modules
python -m pytest tests/ --cov=adapters --cov=processors --cov-report=term-missing

# 3. Processor tests specifically pass
python -m pytest tests/test_processors.py -v

# 4. Adapter tests unchanged
python -m pytest tests/test_supabase_adapter.py -v

# 5. Test count (should be 17 adapter + 8+ processor = 25+)
python -m pytest tests/ -v --co -q | tail -1
```
</verification>

<success_criteria>
- test_processors.py exists with 8+ passing tests
- All processor tests pass (exit code 0)
- All 17 adapter tests still pass (no regressions)
- pytest.ini has --cov=processors in addopts
- conftest.py has ANTHROPIC_API_KEY mock
- Coverage report shows processors/ modules
- Full test suite (adapter + processor tests) passes with exit code 0
</success_criteria>

<output>
After completion, create `.planning/phases/02-copy-modify-processors/02-02-SUMMARY.md`
</output>
